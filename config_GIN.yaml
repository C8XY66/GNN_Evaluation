batch_size:
  - 32
  - 128
learning_rate:
  - 0.01
dropout:
  - 0.5
  - 0.0
hidden_channels:
  - 16
  - 32
  - 64
num_layers:
  - 5
weight_decay:
  - 0.0

